# nlp_sirius_test

Итак, приступаю к тестовому заданию 28.09 22:26

Буду записывать сюда свои идеи и мысли. После прочтения ТЗ появилось много идей

Самое банальное решение - подача в генеративку вопроса с контектом с просьбой найти ответ

Вариант получше - прикрутить RAG. Так и сделаем

В этом случае архитектура будет выглядеть так:
1. Для получения хороших sentence эмбеддингов будем использовать модель intfloat/multilingual-e5-base
2. Сохраняем полученные эмбеддинги в БД (.npy файл)
3. Ищем по трешхолду в БД наиболее похожие эмбеддинги вопросов по cosine_similarity и выдаем соответствующий ответ
4. В случае если нет похожих вопросов - генерим ответ с помощью llama3_8b_4q в реализации ILyaGusev (https://huggingface.co/IlyaGusev/saiga_llama3_8b), выдаем ответ и сохраняем пару вопрос - ответ в БД
5. Оборачиваем все в тг бота с помощью PyTelegramBotAPI и готово


Датасет используем из ТЗ: https://huggingface.co/datasets/kuznetsoffandrey/sberquad
Предварительно удалив строки с пустыми ответами
Он содержит 45к хороших пар вопрос-ответ

Вроде звучит просто и логично
Попробуем реализовать
___
Требования и развертывание:
* Инференс генеративной модели через CPU (llama-cpp-python)
* Получение эмбеддингов через GPU
* RAM >= 16gb
___
Улучшение:
* Модель для создания sentence-эмбеддингов можно зафайнтюнить на парах "вопрос-контекст" из датасета с помощью методов contrastive learning, чтобы улучшить способность модели различать похожие вопросы.
* Модель для генерации можно также дообучить на парах "вопрос-контекст-ответ". Это поможет модели лучше понимать, как формировать ответы на вопросы, опираясь на контекст.
* Попробовать другие подходы, например Information Retrieval + Ranking, сравнить качество
* Инференс через vllm
* Эмбеддинги в векторную БД
* Добавить использование цепочки ответов с помощью langchain
* Обернуть в Docker
* Задеплоить на сервер