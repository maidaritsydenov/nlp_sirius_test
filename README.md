# nlp_sirius_test

Итак, приступаю к тестовому заданию 28.09 22:26. Буду записывать сюда свои идеи и мысли. После прочтения ТЗ появилось много идей

Самое банальное решение - подача в генеративку вопроса с просьбой дать ответ. Вариант получше - прикрутить RAG. Так и сделаем

В этом случае архитектура будет выглядеть так:
1. Для получения хороших sentence эмбеддингов будем использовать модель [intfloat/multilingual-e5-base](https://huggingface.co/intfloat/multilingual-e5-base)
2. Сохраняем полученные эмбеддинги в БД. В моем случае - просто .npy файл
3. Ищем по трешхолду в БД наиболее похожие эмбеддинги вопросов по cosine_similarity и выдаем соответствующий ответ
4. В случае если нет похожих вопросов - генерим ответ с помощью [llama3_8b_4q в реализации ILyaGusev](https://huggingface.co/IlyaGusev/saiga_llama3_8b), выдаем ответ и сохраняем пару вопрос - ответ в БД
5. Оборачиваем все в тг бота с помощью библиотеки [python-telegram-bot](https://docs.python-telegram-bot.org/en/stable/index.html) и готово


[Датасет](https://huggingface.co/datasets/kuznetsoffandrey/sberquad) используем из ТЗ:
Предварительно удалив строки с пустыми ответами
Он содержит 45к хороших пар вопрос-ответ

Вроде звучит просто и логично. Попробуем реализовать
___
Требования и развертывание:
* Скачать модель с [HF карточки модели](https://huggingface.co/IlyaGusev/saiga_llama3_8b_gguf/tree/main) в папку models/saiga_llama3_q4/
* Инференс генеративной модели происходит через CPU (llama-cpp-python)
* Получение эмбеддингов - через GPU
* RAM >= 16gb
___
Улучшение:
* Модель для создания sentence-эмбеддингов можно зафайнтюнить на парах "вопрос-контекст" из датасета с помощью методов contrastive learning, чтобы улучшить способность модели различать похожие вопросы.
* Модель для генерации можно также дообучить на парах "вопрос-контекст-ответ". Это поможет модели лучше понимать, как формировать ответы на вопросы, опираясь на контекст.
* Попробовать другие подходы, например Information Retrieval + Ranking, сравнить качество
* Инференс через vllm
* Эмбеддинги в векторную БД
* Добавить использование цепочки ответов с помощью langchain
* Обернуть в Docker
* Задеплоить на сервер