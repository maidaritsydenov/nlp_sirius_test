# nlp_sirius_test

Итак, приступаю к тестовому заданию 28.09 22:26

Буду записывать сюда свои идеи и мысли

После прочтения ТЗ появилось много идей

Самое банальное решение - подача в генеративку вопроса с контектом с просьбой найти ответ

Вариант получше - RAG. Так и сделаем


В этом случае архитектура будет выглядеть так:
1. Для получения хороших sentence эмбеддингов будем использовать intfloat/multilingual-e5-base
2. Сохраняем полученные эмбеддинги в БД
3. Ищем по трешхолду в БД наиболее похожие вопросы и выдаем ответ
4. В случае если нет похожих вопросов - генерим ответ с помощью Mistral-7B-OpenOrca, выдаем ответ и сохраняем пару вопрос - ответ в БД
5. Оборачиваем все в тг бота с помощью PyTelegramBotAPI и готово


Датасет используем из ТЗ: https://huggingface.co/datasets/kuznetsoffandrey/sberquad
Он содержит 45к вопросов-ответов


Вроде как все просто и логично
Попробуем реализовать

___
Улучшение:
* Модель для создания sentence-эмбеддингов можно зафайнтюнить на парах "вопрос-контекст" из датасета с помощью методов contrastive learning, чтобы улучшить способность модели различать похожие вопросы.
* Модель для генерации можно также дообучить на парах "вопрос-контекст-ответ". Это поможет модели лучше понимать, как формировать ответы на вопросы, опираясь на контекст.
* Попробовать другие подходы, например Information Retrieval + Ranking, сравнить качество
* Обернуть в Docker
* Задеплоить на сервер
* Добавить использование контекста с помощью langchain